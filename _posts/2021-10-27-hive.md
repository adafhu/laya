---
layout:     post
title:      "Hive"
subtitle:   "Hive Tutorial"
date:       2021-10-27 10:45:41
author:     "kgzhang"
catalog: false
category: 
header-style: text
tags:
  - hive
  - bigData
---

## Hive 安装部署

### Ansible 脚本

Hive 及 Mysql 安装我已经做成了 [Ansible 脚本](https://github.com/kougazhang/ansible-galaxy), 有需要可以参考.

### 1.1 选择合适的 Hive 版本, 下载并解压

Hive 2.3.9 (当前 2.x 的最新版本). 

官方下载链接: https://dlcdn.apache.org/hive/hive-2.3.9/

下载压缩包到 `/home` 目录下, 然后解压:

```shell
tar -zxvf apache-hive-2.3.9-bin.tar.gz
```

### 1.2 配置环境变量

> vim /etc/profile

```shell
export HIVE_HOME=/home/apache-hive-2.3.9-bin
export PATH=$HIVE_HOME/bin:$PATH
```

使得环境变量立即生效:

```shell
. /etc/profile
```

### 1.3 修改配置

1. hive-env.sh

如果 `echo $HADOOP_HOME` 的输出不为空, 则说明 `$HADOOP_HOME` 已经配置在环境变量中, 则可以跳过该步骤.

进入安装目录下的 conf/ 目录，拷贝 Hive 的环境配置模板 hive-env.sh.template

cp hive-env.sh.template hive-env.sh
修改 hive-env.sh，指定 Hadoop 的安装路径：

```shell
HADOOP_HOME=/usr/app/hadoop-2.6.0-cdh5.15.2
```

2. hive-site.xml

新建 hive-site.xml 文件，内容如下，主要是配置存放元数据的 MySQL 的地址、驱动、用户名和密码等信息：

```html
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://hadoop001:3306/hadoop_hive?createDatabaseIfNotExist=true</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>root</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>root</value>
  </property>

</configuration>
```

解释该配置文件的几个要点:
- hadoop001 是 mysql 所在的服务器的 hostname;
- 3306 是 mysql 服务的端口
- hadoop_hive 是 Hive 使用的数据库
- 最下面的 2 个 root 要分别替换为 mysql 服务使用的账号及密码.

### 1.4 拷贝数据库驱动

Hive 需要安装驱动(Driver) 才能连接 Mysql. 在 Java 中使用的 Mysql Driver 是 jdbc.

从 Mysql 官网下载该驱动: https://dev.mysql.com/downloads/connector/j/

> Tips: 关于 jdbc 的版本选择: jdbc8 是兼容 Mysql 8, Mysql 5.7.

目前从官网上下载的是一个 rpm 文件, 通过以下命令下载 jdbc jar 包:

```shell
rpm -qpl mysql-connector-java-8.0.22-1.el7.noarch.rpm 
```

一般情况下, 该 jar 会被安装在 `/usr/share/java` 目录下, 把它拷贝到 `$HIVE_HOME/lib`

```shell
cp /usr/share/java/mysql-connector-java.jar $HIVE_HOME/lib
```

### 1.5 初始化元数据库

当使用的 hive 是 1.x 版本时，可以不进行初始化操作，Hive 会在第一次启动的时候会自动进行初始化，但不会生成所有的元数据信息表，只会初始化必要的一部分，在之后的使用中用到其余表时会自动创建；

当使用的 hive 是 2.x 版本时，必须手动初始化元数据库。初始化命令：

```shell
$HIVE_HOME/bin/schematool -dbType mysql -initSchema
```

### 1.6 启动

由于已经将 Hive 的 bin 目录配置到环境变量，直接使用以下命令启动，成功进入交互式命令行后执行 show databases 命令，无异常则代表搭建成功。

命令: `hive`

在 Mysql 中也能看到 Hive 创建的库和存放元数据信息的表


## 参考资料
- [Hive Official Document](https://hive.apache.org/)
- [Linux环境下Hive的安装](https://github.com/kougazhang/BigData-Notes/blob/master/notes/installation/Linux%E7%8E%AF%E5%A2%83%E4%B8%8BHive%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2.md)

