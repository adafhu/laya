---
layout:     post
title:      "hdfs"
subtitle:   ""
date:       2021-08-23 20:16:00
author:     "kgzhang"
catalog: false
category: bigData
header-style: text
tags:
  - hdfs
  - bigData
---

## hdfs 常用命令
- `hdfs dfs -ls`
 - 可以使用通配符: `hdfs dfs -ls /logs/*/raw/*`
 - 递归显示：`hdfs dfs -ls -r <path>`

## namenode 相关命令
+ 查看配置的 namenode: hdfs getconf -namenodes
+ 测试 namenode 是否健康. 没有输出时表示节点健康
    + hadoop fs -test -e hdfs://<Name node>/
    + hdfs haadmin -checkHealth <serviceId>
    
## namenode 部署
- namenode 的机器需要单独部署, 如果网络状况差, zookeeper 探测失败的话会进行 namenode 的主备切换.
    
## namenode HA 高可用
使用 zookeeper 开启 HA 后, 当前 active namenode 有问题后会自动切换.

在开启自动切换的模式下, 不允许手动指定 active namenode, 因为会造成脑裂问题. 可以使用 `hdfs haadmin -failover nn1 nn2` 来进行切换.

现在遇到的问题是, nn1 为 active, nn2 为 standby 时使用 `hdfs haadmin -failover nn1 nn2` 可以切换成功. 但是使用 `hdfs haadmin -failover nn2 nn1` 把 nn1 重新切为 active 时失败, 抛出的异常:
```
Operation failed: Mismatched address stored in ZK for NameNode at /<nn2IP>:8020: Stored protobuf was nameserviceId: "logger-v2"
namenodeId: "nn2"
hostname: "***"
port: 8020
zkfcPort: 8019
, address from our own configuration for this NameNode was /<nn2IP>:8020
	at org.apache.hadoop.hdfs.tools.DFSZKFailoverController.dataToTarget(DFSZKFailoverController.java:77)
	at org.apache.hadoop.ha.ZKFailoverController.getCurrentActive(ZKFailoverController.java:724)
	at org.apache.hadoop.ha.ZKFailoverController.doGracefulFailover(ZKFailoverController.java:636)
	at org.apache.hadoop.ha.ZKFailoverController.access$400(ZKFailoverController.java:61)
	at org.apache.hadoop.ha.ZKFailoverController$3.run(ZKFailoverController.java:604)
	at org.apache.hadoop.ha.ZKFailoverController$3.run(ZKFailoverController.java:601)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ha.ZKFailoverController.gracefulFailoverToYou(ZKFailoverController.java:601)
	at org.apache.hadoop.ha.ZKFCRpcServer.gracefulFailover(ZKFCRpcServer.java:94)
	at org.apache.hadoop.ha.protocolPB.ZKFCProtocolServerSideTranslatorPB.gracefulFailover(ZKFCProtocolServerSideTranslatorPB.java:61)
	at org.apache.hadoop.ha.proto.ZKFCProtocolProtos$ZKFCProtocolService$2.callBlockingMethod(ZKFCProtocolProtos.java:1548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)
```
解决方案: 
- `/sbin/hadoop-daemon.sh stop namenode`, 把 nn2 上的 namenode 停掉
- `hdfs zkfc -formatZK`, 再次初始化 zookeeper, 这样 nn1 就为主了
- `/sbin/hadoop-daemon.sh start namenode`, 重启 nn2

## datanode

启动 datanode

```shell
sbin/hadoop-daemon.sh start datanode
```

### 新增 datanode
只需配置相应的主机IP，然后在在本机上启动datanode，便可以将其注册到master中，并不需要在master的slaves中添加相应的ip 。

但这样未在master中配置的datanode可以并使用，但在master中使用stop-all.sh  时并不能将其停止掉 ，当然再次利用start-all.sh时也不能将其启动起来 。
