---
layout:     post
title:      "The BigData Overview"
subtitle:   ""
date:       2021-11-04 14:59:15
author:     "kgzhang"
catalog: false
category: 
header-style: text
tags:
  - bigdata
---

## 大数据的第二个十年，普通开发者的安与危

大家好，我是又拍云的一名低端小码农，但是我今天想和大家分享的题目却很大“在大数据的第二个十年，普通开发者的安与危”。为什么我要分享这么宏大的命题呢？尼古拉斯·赵四曾经说过，“渣渣码农一思考，技术大牛就发笑”。所以这篇文章发出来的主要目的是供大家逗乐解闷，其次是想讨论一下：快 2022 年了这时开始搞大数据是不是好一个的选择，是不是已经晚了？当下工作与大数据没有关联的岗位，在这第二个十年会不会受到它的冲击？

## 乌衣巷
> 朱雀桥边野草花，乌衣巷口夕阳斜。旧时王谢堂前燕，飞入寻常百姓家。

第一个问题: “大数据目前还热不热”？

如果这个问题放到十年之前是不言自明的，那时大数据还是“火箭科技（rocket science）”，套用 Sheryl Sandberg 的话来说，“If you're offered a seat on a rocket ship, don't ask what seat. Just get on”。而今天当初风光无限的 Hadoop 三大发行商已黔驴技穷，Cloudera 先是在 2019 年与宿敌 Hortonworks 合并，又在今年私有化黯然退市。另一个发行商 MapR 被 HPE 收购后，早已泯然众人矣，在当前毫无市场影响力。另外，从 2021 年 4 月 1 日起，Apache 软件基金会（ASF）宣布 19 个将退休的开源项目中，其中 13 个与大数据相关，10 个属于 Hadoop 生态系统。

现在存储海量数据，除了 Hadoop 还有更多的选择方案。如果存储的数据是非结构化数据如图片或音视频，那么选择分布式对象存储更合适。如果存储结构化数据那选择就更多了。现在的分布式数据库不仅功能强大，而且部署和运维也远比 Hadoop 简单，进行数据分析可以直接写 SQL 并不用像 HDFS 那样需要搭配另外的组件。

所以如果你认为大数据就是指 Hadoop 相关的话，那么大数据已经 “凉凉” 。如果你认为 Hadoop 不能代表大数据，那么大数据的研发热度也早已降温。一个多少令人有些惊愕的真相是已经连续几年没有“明星项目” 出现了，阿里力挺的 Flink 开始于 2015 年，“突然” 火起来的 ClickHouse 早在 2016 年就发布了。在大数据初期 Yarn VS Mesos、Hive VS Spark、Flink VS SparkStreaming VS Storm 等开源软件相爱相杀的盛况，已成绝响。

大数据从未像今天这样廉价和方便过。普通开发者想学习了解大数据，啃“生涩”的官方英文文档不再是唯一途径，各种文字、视频教程俯拾皆是, 尝试一下 wordCount (大数据中的“hello world”) 估计在一小时内就可以搞定；大数据从业者也不再是 “高端稀缺人才”，中小型公司也雇得起。更常见的是越来越多的创业公司创办之处就 all in 云服务，需要使用大数据时直接开通相关的云产品即可，连“招聘大数据开发自建大数据集群” 这步也免了；而对各大互联网巨头来说，当前开源的很多大数据组件性能上捉襟见肘，不能满足它们的 “胃口”，纷纷去研发多层一体化存储系统、面向异构硬件的调度支持等前沿技术。

“旧时王谢堂前燕，飞入寻常百姓家”, 大数据“遇冷” 的背后，折射出的是“大数据进入技术普惠和业务大规模应用的阶段”。

## 云和 AI

第二个问题：面对越来越物美价廉的云上的大数据产品，中小公司的自建大数据集群还能坚持多久？

众所周知的是，大数据的诞生背景是谷歌用廉价的小型机撑起了海量的互联网搜索业务。在这需要强调的是，所谓“廉价”是相对于大型机的“昂贵”比较而言。目前我看到的更多情况是小公司营收能力欠佳，精打细算过日子，这种情况下招聘几名专职大数据开发再租上一批比普通 Web 服务器贵上许多的机器来搞大数据，实在是一个不小的负担。所以如果公司的主营业务不是大数据或 AI 方向，大数据只是主打产品的一个子功能或是内部平台功能的话，放弃自建集群裁掉相关开发使用云上的大数据产品，然后按需按量付费，难道不香吗？

确实还有一个隐患：“上云容易下云难”。以国内知名云厂商为例，新开账号初次购买他们的云产品时优惠力度很大，常常会在半价的基础上还能享受到一定的优惠。所以最初上云的时候公司一般欢天喜地，觉得是降本增效的好手段。可惜任你小公司油奸似鬼，也免不了喝云厂商的洗脚水。等到到期续费时就会发现当初的优惠统统不见了，想迁到成本更低廉的云服务商去，你会发现把大量的数据下载同步过去想不“氪金” 的话是多么的困难。而且成了新的云服务商的老客户后，后续也不见得能便宜多少 ... 此外“不只是基础的IaaS层，而是包括PaaS层在内，以及一些协议、端口、适配等，都容易被云平台提供商‘严重‘锁死’，导致客户被深度绑定，从而使得‘上云容易下云难’，形成了一种对云供应商的被动性依赖”。

这两年大火的公司 Snowflake 带来了新的思路。Snowflake 属于 DaaS （Data warehouse As A Service），是基于云服务的提供数据仓库的 SaaS 服务。讲到这可能还是有些同学没太理解，说人话就是 Snowflake 这个公司在各大云厂商的基础服务上做了一个抽象层，然后基于这个抽象层构建自己的数据仓库产品。这样就不太会出现被某个特定的云厂商“绑定” 的情况，还可以根据各云厂商的价格及服务动态调节以控制成本。

如果借鉴 Snowflake 的思路，比如在云厂商的 Hadoop 产品上进行封装一套统一的接口，那对自有大数据集群的需求还有多大呢？或者直接选择 Snowflake 这种第三方的大数据产品，是不是更加的划算呢？如果在成本上公司自有大数据集群比使用云产品要高，那么做为该公司的大数据开发要提供什么样的服务才能说服你的老板不把你优化掉，证明自建拥有更高的综合性价比呢？24 小时 onCall 更快处理故障的速度，更加稳定的集群，还是与兄弟业务部门更加高效的协作产出更大的价值? 

第三个问题：“你负责的业务比无人驾驶还复杂吗?”

在大数据领域，很多公司的数据规模已经是 PB 或 EB 级，海量的数据靠过去的“人海战术” 去分析和运维的成本越来越高，基于人工智能（AI）的能力做系统优化，已经逐渐变成一种新的潮流。大数据会变得越来越智能，“目前这种写各种脚本拖数据，写几千行 SQL 筛数据” 的工种，离被 AI 取代还有多远？

有些开发同学不以为然，认为当下的人工智能就是“人工智障”，沉溺于自己手头工作的细节，强调人工智能目前是多么不靠谱，潜台词是 “自己的工作离被 AI 还远着呢”。如果你也这么想，我要反问一句，“你负责的业务比无人驾驶还复杂吗？” 如果以研发无人驾驶或“阿尔法狗” 的投入力度，你的工作是不是能被 AI 取代？我想这么思考的话，大部分人的回答是肯定的。那么真相就是，不是你的工作无法被 AI 取代，而是你比 AI 便宜很多, 你没有被裁掉是商业成本上的 trade off。

正如同大数据技术上云后成本不断被摊薄，云上的各种 AI 产品价格也越来越亲民，举个例子，当前调用一次人脸识别的接口价格还不到 1 分钱, 现在很多公司的人脸识别都是用的这种第三方接口。《三体》中的降维打击给很多人留下了深刻的印象，“毁灭你，与你有何相干？”，大数据技术和 AI 技术的成熟，AI For System 落地后带来的很可能是开发方式上翻天覆地的变化，此时你可能还服气，幻想着将来的某天与 AI 掰掰手腕，但很可能在 AI 技术的加持下，你所在的职业已经被优化掉了，就好比现在专职做 ETL 的和 DBA 的就越来越少了。


## 夸父逐日
> 夸父与日逐走，入日；渴，欲得饮,饮于河，渭；河，渭不足，北饮大泽。未至，道渴而死。弃其杖，化为邓林。

AI 已是不可抗拒的潮流, 为 AI 提供数据支持的大数据也会随之昌明。搞 AI 的炼丹师们举着筷子吃肉，搞大数据的矿工们端着大碗喝汤，这不过分吧？所以担心大数据饭碗问题的同学可以把心放到肚子里了，但是在中小型公司想不关心业务仅提供大数据支持服务肯定是越来越行不通的，因为这块市场被云服务侵占的越来越厉害了。

作为普通的开发者该怎么办？去 Github 上的项目下留言 “学不动了” 之类的事情，我们肯定不能去做，实在太丢人现眼了。应有夸父之姿，对技术常怀赤子之心，积极地拥抱技术浪潮，坚持长期主义而不是投机心态在一个行业深耕，这样或许会迎来从追逐者到引领者的蜕变。展开来讲，我觉得有以下几个点：

### 定投半衰期长的知识

定投是一个投资上的概念，指定期定额投资某种金融产品。“半衰期是一个物理学概念，指的是放射性物质减少一半质量（辐射衰弱）所需的时间。信息也有半衰期。信息的半衰期指的是，一半的信息量变得无关紧要或者彻底过时所需的时间。” 定投半衰期长的知识，可以理解为坚持不断地学习不容易过时的知识。这看上去像是正确的废话，大数据领域哪些算的上是半衰期长的知识呢？我能想到的有这 2 个：Java 和开源项目背后的论文。

目前来看 Java 是一门保值的语言, 无论是企业级的后台开发还是大数据方面都有非常广泛的应用。最近几年的数据湖 Hudi、Iceberg 还是号称取代 Hadoop 的 Ozone 都依旧基于 Java 构建。所以定投 Java，夯实语言基础，无论是大数据业务开发还是深刻理解开源项目源码都必不可少。

大数据的相关组件数量之多，给人一种“乱花渐欲迷人眼”的感觉，但是这些琳琅满目的项目力图去解决的问题却从未改变。所以如果止步满足于掌握当前最流行的大数据项目的 API，就会陷入“学而不思则罔”的典型症状中，疲于追赶，乃至发出“学不动”了感叹。啃一啃项目背后的论文，揣摩各项目在因果关系链上的脉络，从项目的原理出发去提纲挈领地学习和实践，才能在后续的工作中起到事半功倍的效果。

### 拥抱云和 AI

不谋全局者，不足谋一域。做出正确选择的第一步是对全局形势作出了正确的判断。举个例子，如果你明白云和 AI 是当前的一个大势，那你看大数据分析引擎 Flink 近期版本迭代是朝着“支持 Flink on K8S” 和“发展 PyFlink 的客户端”的方向发展也就不足为奇了。进一步分析，如果想向 Flink 社区共享代码，朝着上述方向去努力是能快速地得到 Commmiter 的支持的。

这里还想着重强调的是 AI 技术，AI 和大数据很可能发展成像 Mysql、Redis 等一样普及的工具。既然无法绕过它，那何不把它纳入你的编程武器库。可能我们做不到像专职的机器学习工程师那样精通，但是熟悉和掌握一些业已成熟的工具和方法，和我们手头的业务相互融合碰撞，说不准就能有惊人的收获!

### 在一个行业沉淀五到十年

显而易见的是，热门行业的各方面待遇确实比远高于平均水平。但是“热门行业”是不断变化的，当前热门行业的领军人物是从其他行业转过来的佼佼者终归是少数，大部分领跑者还是早已在该行业浸淫已久的领域专家。只不过是该行业变得热门后，这些人才被放到了镁光灯下成为我们眼中的幸运儿。所以在一个行业坚持五到十年，沉淀该行业特有的领域还是非常有必要的。

为什么是五到十年呢？那篇盛名已久的《十年学会编程》中曾引用过这样一个研究 “研究表明 (Hayes，Bloom)在 任何一种领域内，象下棋、作曲、绘画、钢琴演奏、游泳、网球、以及原子物理学和拓 扑学，等等，要达到专家水平大约都要化十年时间”。中国古诗中也有“十年磨一剑，霜刃未曾试” 的金句。所以把自己打磨成某一个领域的专业，应该真的需要十年这么久。那为什么在这里又要给这个期限加上一个弹性，称之为“五到十年”呢？因为中国是一个飞速发展充满变数的神奇国度，你选择了P2P、虚拟币或在线教育等行业，“树欲静而风不止” 想不变都难吧。

谢谢大家听我絮絮叨叨地讲了这么久。如果上文观点与您的见解不同，那肯定是我错了，毕竟我从事大数据相关的工作不足一年，难免漏洞百出。望各位读者大大们海涵，如若留言赐教更是拜谢不尽。

## 参考资料
- 11 天里 13 个 Apache 开源项目宣布退休，Hadoop 的时代结束了 ， https://www.infoq.cn/article/8iproq9a7qxuslmpurfo
- “后红海时代”，独家揭秘当下大数据体系， https://developer.aliyun.com/topic/download?id=7984
- 凭什么“上云容易下云难”，https://tech.ifeng.com/c/87sNFmq3EWF
- Snowflake：数据仓库的终极形态？https://zhuanlan.zhihu.com/p/54439354
- 科技爱好者周刊：第 103 期, https://www.ruanyifeng.com/blog/2020/04/weekly-issue-103.html
- 十年学会编程, http://daiyuwen.freeshell.org/gb/misc/21-days-cn.html
