---
layout:     post
title:      "Golang Parallel 02: Memory model"
subtitle:   ""
date:       2021-12-19 15:44:48
author:     "kgzhang"
catalog: false
category: golang
header-style: text
tags:
  - golang
---

## 资料
- 官方文档：https://golang/org/ref/mem
- 翻译：https://www.jianshu.com/p/5e44168f47a3
- Happen Before
- COW
- Single Machine Word
- 扩展：MESI，CPU 通知其他 CPU 过期掉 store buffer 中的缓存

## Memory model
编译器和 CPU 为了优化程序，在不影响程序语义的情况下，可能会对代码进行重排。对于我们编写程序造成的影响是，涉及到对共享内存的访问，一定要加锁或使用 channel。

### Happen-Before(先行发生)
在一个 goroutine 中，读和写一定是按照程序中的顺序执行的，即编译器和处理器只有在不会改变这个 goroutine 的行为时才可能修改读和写的执行顺序。但是由于重排，其他 goroutine 看到的代码执行顺序可能是不同的。

比如一个 goroutine 执行 `a=1;b=2`, 另一个 goroutine 可能看到 b 在 a 之前更新。

定义 Happen-Before: 如果事件 e1 发生在 e2 前，我们可以说 e2 发生在 e1 后。如果 e1 不发生在 e1 前也不发生在 e2 后，我们就说 e1 和 e2 是并发的。

> 在单一的独立的 goroutine 中先行发生(Happen Before)的顺序即是程序中表达的顺序。

其实 happen before 的顺序就是单线程中符合人直觉的代码顺序。

当下面条件满足时，对于变量 v 的读操作 r 是允许看到对 v 的写操作 w 的：（如何能读取到变量 v 修改后的值）
- r 不先行发生于 w。（读r 这个动作是在修改 w 后进行的）
- 在 w 后 r 前没有对 v 的其他写操作（在修改 w 后读取 r 前没有其他的修改操作，否则的话刚才的写操作就被覆盖了）

为了保证 r 一定能看到对 v 的写操作 w，应满足如下条件：
- w 先行发生于 r （写操作要比读操作先执行）
- 其他对共享变量 v 的写操作要么在 w 之前要么在 r 之后，（在 w 之前就会被 w 覆盖，在 r 之后不影响 r 的读取）

总结：Happen Before 是要求赋值原子且能看到别人的写操作。

### goroutine 中的 memory model
在单个 goroutine 中可以理解为就是一个线程，其中没有并发，遵循上述的 Happen Before 的模型。

多个 goroutine 中必须使用同步事件来建立先行发生（Happen Before) 这一个条件来保证读操作能看到要写的操作。
- 对变量 v 的零值初始化在内存模型中等同于写操作（声明变量就是一个写操作）
- 对大于 Single machine word 的变量的读写操作表现的像以不确定顺序对多个 single machine word 的变量的操作。

#### Single Machine Word?
对于 64 位的机器，一个指针的大小是 8 bytes(字节)，一个 8 个字节的一个赋值它是原子的（也就是 CPU 一口气干完，不存在一个中间状态）, 是一个机器字或者机器码。

- 比如一个变量 v，v 是一个 int 的一个指针，那么把它赋值给变量 a 或变量b 时，这个动作是原子的。
- 非原子：赋值一个 50 byte 的数组，CPU 需要把值一次次的刷到对应的内存位置，这就是非原子的。在某个时刻存在已经数组的内存地址已经写了一半但是没写完的时候。

使用 Machine Word 实现无锁并发, COW。

线程安全的方式：使用 `atomic.Value`, 使用 load 和 store，用它来存储变量的指针和赋值。（这样就会安全很多，因为能够满足可见性的要求）。

其他不线程安全的操作：
- interface 的赋值
- slice 的赋值

#### COW
COW, Copy On Write, 以 map 为例。新申请一个 map 把老的 map 中的值拷到新的 map 中去，再使用老 map 的指针指向新的 map。

COW 能够保证赋值动作是原子的（因为赋值给新 map 时，新 map 已经创建完成了，不存在中间状态了）。

但是 COW 不满足可见性的要求，因为 CPU 存在 store buffer, 可能会出现在线程1 中指向的是老的地址，线程2中指向的是新的地址。

Single Machine Word 也与 Golang 中的内存对齐有关。

redis 中对 COW 的使用: BGSAVE（数据持久化）

参考：https://zhuanlan.zhihu.com/p/339437815

简述：fork 一个新的进程共享原来进程的物理内存，然后对里面的数据拷贝进行刷盘。这时的刷盘相当于拿到了一个副本，redis 把被变化的部分拷出去刷到磁盘中。

问题概述：
1. RDB的过程中是否会停止对外提供服务？
2. RDB的过程中数据修改了，备份的是修改前的还是修改后的？
3. RDB时是不是先把内容中的所有KV复制一份，保证数据不会被修改？

问题解决：使用Copy On Write 写时复制

详细
在看Redis持久化方式中的RDB方式时，想到了几个问题：

1.  Redis是单线程的，那在RDB的过程中，是不是就没法对外提供服务了？
Redis操作快的一个重要原因是Redis的数据是在内存中存储和操作的，持久化本身是磁盘的IO操作，IO操作又是特别耗时的，RDB备份的过程对Redis来说是挺漫长的，如果Redis没法对外提供服务的话，对Redis的影响是很大的吧；
2. 知道备份时不会阻塞对外服务，那在数据备份的过程中，有新的数据变更的操作发生时，备份的是变更前的数据还是变更后的数据呢？
另一个角度：RDB快照的是精确的一个时刻的内存数据呢？还是一段时间内的内存数据？
另一个角度：RDB快照是精确的还是模糊的？
3. 既然是数据备份，在开始备份的时候，是不是要把Redis的所有数据现在内存中拷贝一份呢？那样的话平时Redis服务器的内存利用率就不能大于50%了啊？

解答

1. RDB过程中会fork一个子进程，子进程做数据备份操作，主进程继续对外提供服务，所有Redis服务不会阻塞；
2. Copy On Write 机制，备份的是开始那个时刻内存中的数据；
3. Copy On Write 机制不需要把整个内存的数据都复制一份；

Copy On Write 机制

核心思路：fork一个子进程，只有在父进程发生写操作修改内存数据时，才会真正去分配内存空间，并复制内存数据，而且也只是复制被修改的内存页中的数据，并不是全部内存数据；

Redis中执行BGSAVE命令生成RDB文件时，本质就是调用Linux中的fork()命令，Linux下的fork()系统调用实现了copy-on-write写时复制；

fork()是类Unix操作系统上创建线程的主要方法，fork用于创建子进程（等同于当前进程的副本）；

传统的普通进程复制，会直接将父进程的数据拷贝到子进程中，拷贝完成后，父进程和子进程之间的数据段和堆栈是相互独立的；

copy-on-write技术，在fork出子进程后，与父进程共享内存空间，两者只是虚拟空间不同，但是其对应的物理空间是同一个；

Linux中CopyOnWrite实现原理

fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。

CopyOnWrite的好处：
1. 减少分配和复制资源时带来的瞬时延迟；
2. 减少不必要的资源分配；

CopyOnWrite的缺点：
1. 如果父子进程都需要进行大量的写操作，会产生大量的分页错误（页异常中断page-fault）;

Redis中的CopyOnWrite

Redis在持久化时，如果是采用BGSAVE命令或者BGREWRITEAOF的方式，那Redis会fork出一个子进程来读取数据，从而写到磁盘中。

总体来看，Redis还是读操作比较多。如果子进程存在期间，发生了大量的写操作，那可能就会出现很多的分页错误(页异常中断page-fault)，这样就得耗费不少性能在复制上。

而在rehash阶段上，写操作是无法避免的。所以Redis在fork出子进程之后，将负载因子阈值提高，尽量减少写操作，避免不必要的内存写入操作，最大限度地节约内存。

## Memory Reordering
> 内存重排, memory reordering

用户写下的代码，先要编译成汇编代码，也就是各种指令，包括读写内存的指令。CPU的设计者们，为了榨干 CPU 的性能，会使用很多优化手段，比如流水线、分支预测等。其中为了提高读写内存的效率，会对读写指令进行重排，这就是内存重排。

比如：

```python
x = 0
for i in range(100):
    x = 1
    print x

编译器可能优化成：
```python
x = 1
for i in range(100):
    print x
```
这种优化对于单线程来说是没有任何区别，但是如果这段代码是并行的，此时有另外一个线程修改 x 的值，那么这段代码的优化就是有问题的。

例子2：

比如有 2 个线程，线程1 执行 `a=1;print(b)`, 线程2执行 `b=1;print(a)`，那么有没有可能两个线程打印的都是 `0`

现代 CPU 为了“抹平”内核、内存、硬盘之间的速度差异，会设置不同级别的缓存，比如 CPU 中存在三级缓存。示例如下：

```
CPU 指令层
---
store buffer 层
---
L1 Cache
---
L2 Cache
---
L3 Cache
```

当 CPU 执行完指令后，会先将结果暂存在 store buffer, 后续查找时再按照 storebuffer -> L1/L2/L3 的顺序进行查找。这种设计对于单线程来说十分完美。但是在多线程下就可能出现问题。

如上述提到的 2 个线程的问题，线程1和2 同时执行，它们分别修改完 a 与 b 的值后缓存在 store buffer 中，没有刷到内存中。那么这两个线程在执行 print 操作时就只能访问到 a 与 b 在内存中的初始值 0, 所以打印出来都是 0.

### 锁到底是什么？
从上述例子可知，对于多线程的程序，所有的 CPU 都会提供“锁”支持，称之为barrier 或则 fence。（也就是内存屏障）

内存屏障 （Memory Barrier) 又称之为内存栅栏，是一个 CPU 指令，它的作用有两个：
- 一是保证特定操作的执行顺序。编译器和处理器都能进行指令重排，但是插入了 Memory Barrier 后，则编译器和 CPU 就知道了不能怼 Memory Barrier 中间的指令进行重排。
- 二是保证某些变量的内存可见性。强制把 CPU 的缓存数据刷到内存中，因此 CPU 上的线程都能读到这些数据的最新版本。

各语言对内存屏障的实现：
- Java: volatile 关键字
- Golang: sync.Mutex

